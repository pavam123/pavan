{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "mDgbUHAGgjLW",
        "O_i_v8NEhb9l",
        "HhfV-JJviCcP",
        "Y3lxredqlCYt",
        "3RnN4peoiCZX",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "JlHwYmJAmNHm",
        "35m5QtbWiB9F",
        "PoPl-ycgm1ru",
        "H0kj-8xxnORC",
        "nA9Y7ga8ng1Z",
        "PBTbrJXOngz2",
        "u3PMJOP6ngxN",
        "dauF4eBmngu3",
        "bKJF3rekwFvQ",
        "MSa1f5Uengrz",
        "GF8Ens_Soomf",
        "0wOQAZs5pc--",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "KSlN3yHqYklG",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "EM7whBJCYoAo",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "4Of9eVA-YrdM",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "bamQiAODYuh1",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "OH-pJp9IphqM",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "PIIx-8_IphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "YJ55k-q6phqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "g-ATYxFrGrvw",
        "Yfr_Vlr8HBkt",
        "8yEUt7NnHlrM",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "yLjJCtPM0KBk",
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pavam123/pavan/blob/main/Productionization_of_ML_Systems_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    -\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - EDA/Regression\n",
        "##### **Contribution**    - Individual\n",
        "my name : ch pavan kumar"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TROkClrMNMEN"
      },
      "source": [
        "# **Project Summary -**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6v_1wHtG2nS"
      },
      "source": [
        "In the realm of travel and tourism, the intersection of data analytics and machine learning presents an opportunity to revolutionize the way travel experiences are curated and delivered. This capstone project revolves around a trio of datasets - users, flights, and hotels - each providing a unique perspective on travel patterns and preferences. The goal is to leverage these datasets to build and deploy sophisticated machine learning models, serving a dual purpose: enhancing predictive capabilities in travel-related decision-making and mastering the art of MLOps through hands-on application."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i197DskNNMEO"
      },
      "source": [
        "# **GitHub Link -**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/pavam123/Capstone-project-of-Hotel-Booking-Analysis/blob/main/Productionization_of_ML_Systems_Regression.ipynb"
      ],
      "metadata": {
        "id": "i80Ilic_NvNR"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tX4hC-ANMEP"
      },
      "source": [
        "# **Problem Statement**\n",
        "\n",
        "This capstone project revolves around a trio of datasets - users, flights, and hotels - each providing a unique perspective on travel patterns and preferences. The goal is to leverage these datasets to build and deploy sophisticated machine learning models, serving a dual purpose: enhancing predictive capabilities in travel-related decision-making and mastering the art of MLOps through hands-on application.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2F5T-NOBogSx"
      },
      "source": [
        "# **Project Objectives**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpeJGUA3kjGy"
      },
      "source": [
        "**1. Regression Model Development:**\n",
        "\n",
        "Build a regression model to predict the price of a flight using the flights.csv dataset. Focus on feature selection, model training, and validation to ensure accuracy and reliability.\n",
        "\n",
        "**2. REST API for Regression Model:**\n",
        "\n",
        "Develop a REST API using Flask to serve the flight price prediction model, enabling real-time price predictions.\n",
        "\n",
        "**3. Containerization:**\n",
        "\n",
        "Package and deploy the flight price prediction model using Docker, ensuring portability and ease of deployment.\n",
        "\n",
        "**4. Kubernetes for Scalability:**\n",
        "\n",
        "Deploy the model using Kubernetes to manage scalability and handle varying loads efficiently.\n",
        "\n",
        "**5. Automated Workflows with Apache Airflow:**\n",
        "\n",
        "Design and implement automated workflows for managing the travel data, specifically for the regression models. Develop Directed Acyclic Graphs (DAGs) to orchestrate complex workflows in an efficient and manageable way.\n",
        "\n",
        "**6. CI/CD Pipeline with Jenkins:**\n",
        "\n",
        "Implement a Continuous Integration/Continuous Deployment (CI/CD) pipeline using Jenkins for consistent and reliable deployment of the travel price prediction model.\n",
        "\n",
        "**7. Model Tracking with MLFlow:**\n",
        "\n",
        "Utilize MLFlow for tracking and managing different versions of the travel price prediction model, ensuring a systematic approach to model iteration and deployment.\n",
        "\n",
        "**8. Gender Classification Model:**\n",
        "\n",
        "Deploy a classification model to categorize a user's gender.\n",
        "\n",
        "**9. Travel Recommendation Model:**\n",
        "\n",
        "Build a recommendation model to provide hotel suggestions based on user preferences and historical data. Develop a Streamlit web application to display insights and visualizations derived from the deployed travel recommendation model, offering an interactive and user-friendly interface for data exploration."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yh0H0n-XNMER"
      },
      "source": [
        "# **General Guidelines** : -  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPSfU5sgNMER"
      },
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Regression Model Development:**\n",
        "\n",
        "Build a regression model to predict the price of a flight using the flights.csv dataset. Focus on feature selection, model training, and validation to ensure accuracy and reliability."
      ],
      "metadata": {
        "id": "Zzu4W2doVohd"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_i_v8NEhb9l"
      },
      "source": [
        "# ***Let's Begin !***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhfV-JJviCcP"
      },
      "source": [
        "## ***1. Know Your Data***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3lxredqlCYt"
      },
      "source": [
        "### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tdzJqRXlJ_9K"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Import Libraries\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import datetime as dt\n",
        "\n",
        "## Statistics Library\n",
        "import scipy.stats as stats\n",
        "\n",
        "## Data Visualisation Libraray\n",
        "import matplotlib.pyplot as plt\n",
        "import pylab\n",
        "import seaborn as sns\n",
        "\n",
        "## Machine Learning\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.linear_model import ElasticNet\n",
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "## Importing essential libraries to check the accuracy\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "\n",
        "## Warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJPLtZwUKiJQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error as mse\n",
        "from sklearn.metrics import r2_score\n",
        "from math import sqrt\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "from prettytable import PrettyTable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RnN4peoiCZX"
      },
      "source": [
        "### Dataset Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "outputs": [],
      "source": [
        "# Load Dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZznhS2JFmTGJ"
      },
      "outputs": [],
      "source": [
        "flights_df=pd.read_csv(\"/content/flights.csv\")\n",
        "hotels_df=pd.read_csv(\"/content/hotels.csv\")\n",
        "users_df=pd.read_csv(\"/content/users.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x71ZqKXriCWQ"
      },
      "source": [
        "### Dataset First View"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "outputs": [],
      "source": [
        "# Dataset First Look\n",
        "flights_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cb5-__Hpm8Xq"
      },
      "outputs": [],
      "source": [
        "flights_df.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Dh89DdiDFvZ"
      },
      "source": [
        "**Flights Dataset:**\n",
        "\n",
        "travelCode: Identifier for the travel.\n",
        "\n",
        "userCode: User identifier(linked to the Users dataset)\n",
        "\n",
        "from: Origin of the flight.\n",
        "\n",
        "to: Destination of the flight.\n",
        "\n",
        "flightType: Type of flight (e.g., first class).\n",
        "\n",
        "price: Price of the flight.\n",
        "\n",
        "time: Flight duration.\n",
        "\n",
        "distance: Distance of the flight.\n",
        "\n",
        "agency: Flight agency.\n",
        "\n",
        "date: Date of the flight."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ezRhd8gPnT8w"
      },
      "outputs": [],
      "source": [
        "hotels_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N0MuLZ4LnY3L"
      },
      "outputs": [],
      "source": [
        "hotels_df.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYZP8XJaDKcb"
      },
      "source": [
        "**Hotels Dataset:**\n",
        "\n",
        "travelCode: Identifier for the travel, similar to the Flights dataset.\n",
        "\n",
        "userCode: User identifier(linked to the Users dataset)\n",
        "\n",
        "name: Name of the hotel.\n",
        "\n",
        "place: Location of the hotel.\n",
        "\n",
        "days: Number of days of the hotel stay.\n",
        "\n",
        "price: Price per day.\n",
        "\n",
        "total: Total price for the stay.\n",
        "\n",
        "date: Date of the hotel booking."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ltBh4TlXndBz"
      },
      "outputs": [],
      "source": [
        "users_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Epmgb67Rnk_G"
      },
      "outputs": [],
      "source": [
        "users_df.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1R8dPgCDOfT"
      },
      "source": [
        "**Users Dataset:**\n",
        "\n",
        "code: User identifier.\n",
        "\n",
        "company: Associated company.\n",
        "\n",
        "name: Name of the user.\n",
        "\n",
        "gender: Gender of the user.\n",
        "\n",
        "age: Age of the user."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hBIi_osiCS2"
      },
      "source": [
        "### Dataset Rows & Columns count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "outputs": [],
      "source": [
        "# Dataset Rows & Columns count\n",
        "flights_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GgYG-N_cnzZP"
      },
      "outputs": [],
      "source": [
        "hotels_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hUrwjwOnn2sD"
      },
      "outputs": [],
      "source": [
        "users_df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlHwYmJAmNHm"
      },
      "source": [
        "### Dataset Information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "outputs": [],
      "source": [
        "# Dataset Info\n",
        "flights_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VwHF5XbKqesx"
      },
      "outputs": [],
      "source": [
        "hotels_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sZvqowIYqluI"
      },
      "outputs": [],
      "source": [
        "users_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35m5QtbWiB9F"
      },
      "source": [
        "#### Duplicate Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "outputs": [],
      "source": [
        "# Dataset Duplicate Value Count\n",
        "flights_df.duplicated().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HAYWzxmoqwZI"
      },
      "outputs": [],
      "source": [
        "hotels_df.duplicated().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xvXP0J_0qzJz"
      },
      "outputs": [],
      "source": [
        "users_df.duplicated().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PoPl-ycgm1ru"
      },
      "source": [
        "#### Missing Values/Null Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "outputs": [],
      "source": [
        "# Missing Values/Null Values Count\n",
        "flights_df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xqT3PVa-rVfV"
      },
      "outputs": [],
      "source": [
        "hotels_df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L4Dly-KBrZDU"
      },
      "outputs": [],
      "source": [
        "users_df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0kj-8xxnORC"
      },
      "source": [
        "### What did you know about your dataset?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfoNAAC-nUe_"
      },
      "source": [
        "**We have three datasets:**\n",
        "\n",
        "**Flights Dataset:** *This dataset contains approximately 271,000 entries across 11 columns, including 'travelCode', 'userCode', 'from', 'to', 'flightType', 'price', 'time', 'distance', 'agency', and 'date'.*\n",
        "\n",
        "**Hotels Dataset:** *This dataset has around 40,000 entries and includes 8 columns: 'travelCode', 'userCode', 'name', 'place', 'days', 'price', 'total', and 'date'.*\n",
        "\n",
        "**Users Dataset:** *This dataset consists of about 1,400 rows with 5 columns: 'code', 'company', 'name', 'gender', and 'age'.*\n",
        "\n",
        "*All datasets columns are free from duplicate and null values.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      },
      "source": [
        "## ***2. Understanding Your Variables***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "outputs": [],
      "source": [
        "# Dataset Columns\n",
        "flights_df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SjTyiADGroFn"
      },
      "outputs": [],
      "source": [
        "hotels_df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EFgDkerTrq2T"
      },
      "outputs": [],
      "source": [
        "users_df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "outputs": [],
      "source": [
        "# Dataset Describe\n",
        "flights_df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MzABWWYdr7Ee"
      },
      "outputs": [],
      "source": [
        "hotels_df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jejm64IhsBtL"
      },
      "outputs": [],
      "source": [
        "users_df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBTbrJXOngz2"
      },
      "source": [
        "### Variables Description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJV4KIxSnxay"
      },
      "source": [
        "**Flights Dataset:**\n",
        "\n",
        "travelCode: Identifier for the travel.\n",
        "\n",
        "userCode: User identifier(linked to the Users dataset)\n",
        "\n",
        "from: Origin of the flight.\n",
        "\n",
        "to: Destination of the flight.\n",
        "\n",
        "flightType: Type of flight (e.g., first class).\n",
        "\n",
        "price: Price of the flight.\n",
        "\n",
        "time: Flight duration.\n",
        "\n",
        "distance: Distance of the flight.\n",
        "\n",
        "agency: Flight agency.\n",
        "\n",
        "date: Date of the flight.\n",
        "\n",
        "**Hotels Dataset:**\n",
        "\n",
        "travelCode: Identifier for the travel, similar to the Flights dataset.\n",
        "\n",
        "userCode: User identifier(linked to the Users dataset)\n",
        "\n",
        "name: Name of the hotel.\n",
        "\n",
        "place: Location of the hotel.\n",
        "\n",
        "days: Number of days of the hotel stay.\n",
        "\n",
        "price: Price per day.\n",
        "\n",
        "total: Total price for the stay.\n",
        "\n",
        "date: Date of the hotel booking.\n",
        "\n",
        "**Users Dataset:**\n",
        "\n",
        "code: User identifier.\n",
        "\n",
        "company: Associated company.\n",
        "\n",
        "name: Name of the user.\n",
        "\n",
        "gender: Gender of the user.\n",
        "\n",
        "age: Age of the user."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3PMJOP6ngxN"
      },
      "source": [
        "### Check Unique Values for each variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "outputs": [],
      "source": [
        "# Check Unique Values for each variable.\n",
        "flights_df.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rKNcgXSnsNVU"
      },
      "outputs": [],
      "source": [
        "hotels_df.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wxNhLZTPsP3S"
      },
      "outputs": [],
      "source": [
        "users_df.nunique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dauF4eBmngu3"
      },
      "source": [
        "## 3. ***Data Wrangling***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKJF3rekwFvQ"
      },
      "source": [
        "### Data Wrangling Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "outputs": [],
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "flights_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApWd8H-QC_cG"
      },
      "source": [
        "**Flights Dataset:**\n",
        "\n",
        "travelCode: Identifier for the travel.\n",
        "\n",
        "userCode: User identifier(linked to the Users dataset)\n",
        "\n",
        "from: Origin of the flight.\n",
        "\n",
        "to: Destination of the flight.\n",
        "\n",
        "flightType: Type of flight (e.g., first class).\n",
        "\n",
        "price: Price of the flight.\n",
        "\n",
        "time: Flight duration.\n",
        "\n",
        "distance: Distance of the flight.\n",
        "\n",
        "agency: Flight agency.\n",
        "\n",
        "date: Date of the flight."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1dSCLxj5DebY"
      },
      "outputs": [],
      "source": [
        "flights_df['from'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gZTCB990D7sr"
      },
      "outputs": [],
      "source": [
        "flights_df['to'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2afUA-lgEDjQ"
      },
      "outputs": [],
      "source": [
        "flights_df['flightType'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XWoCNAN9EKIu"
      },
      "outputs": [],
      "source": [
        "flights_df['agency'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZXSBQEIzEN6j"
      },
      "outputs": [],
      "source": [
        "flights_df['route']=flights_df['from']+'-'+flights_df['to']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JTx-ZCnfMmMp"
      },
      "outputs": [],
      "source": [
        "flights_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lnuxswBRMv48"
      },
      "outputs": [],
      "source": [
        "flights_df['route'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ELrEYoEM5j3"
      },
      "outputs": [],
      "source": [
        "def convert_time(time):\n",
        "  hour=int(time)\n",
        "  minute=time-hour\n",
        "  totalmin=int(hour*60)+int(minute*100)\n",
        "  return totalmin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8odT-MluRgIN"
      },
      "outputs": [],
      "source": [
        "convert_time(1.66)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RVDQnUHbRyip"
      },
      "outputs": [],
      "source": [
        "flights_df['total_time']=flights_df['time'].apply(convert_time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "flcTOCQrR43j"
      },
      "outputs": [],
      "source": [
        "flights_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vx4TcppHSedR"
      },
      "outputs": [],
      "source": [
        "flights_df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kMAE9CGZd3_m"
      },
      "outputs": [],
      "source": [
        "flights_df['date'] = pd.to_datetime(flights_df['date'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xAmx4idteB1I"
      },
      "outputs": [],
      "source": [
        "flights_df['weekday_num']   = flights_df.date.dt.weekday\n",
        "flights_df['month']         = flights_df.date.dt.month\n",
        "flights_df['year']          = flights_df.date.dt.year\n",
        "flights_df['weekday']=flights_df['date'].dt.day_name()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W5EUHawWjP5R"
      },
      "outputs": [],
      "source": [
        "#Calculate Speed in km/hr for further insights\n",
        "flights_df['speed'] = (flights_df.distance/(flights_df.total_time/60))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XRGUopowjZsw"
      },
      "outputs": [],
      "source": [
        "flights_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSa1f5Uengrz"
      },
      "source": [
        "### What all manipulations have you done and insights you found?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbyXE7I1olp8"
      },
      "source": [
        "*In our flight dataset, we have three seat types: first-class, premium, and economy. The agency column includes three major agencies: Rainbow, Cloudy, and FlyingDrops.*\n",
        "\n",
        "*Additionally, I created a new feature called 'flight route' by combining the 'from' and 'to' columns. The 'time' column has been converted into minutes, and new features were generated from the 'date' column, including weekend number, month, day, year, and weekday. I also introduced a 'speed' feature, calculated using the 'distance' and 'time' columns.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GF8Ens_Soomf"
      },
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wOQAZs5pc--"
      },
      "source": [
        "#### Chart - 1 Catplot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "outputs": [],
      "source": [
        "# Chart - 1 visualization\n",
        "\n",
        "sns.catplot(y = \"price\", x = \"agency\", data = flights_df.sort_values(\"price\", ascending = False), kind=\"boxen\", height = 8, aspect = 3,hue='agency',palette=\"viridis\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5QZ13OEpz2H"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XESiWehPqBRc"
      },
      "source": [
        "*I created a catplot graph to analyze the price distribution across different agencies. This graph provides a comprehensive view of price variations among agencies, highlighting the median and visualizing price ranges. It helps us understand how ticket bookings are distributed across various price ranges.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_j1G7yiqdRP"
      },
      "source": [
        "*After carefully analyzing the graph, I found that most people book tickets in the price range of $800 to $1200. However, the average price for tickets booked through the agency FlyingDrops is notably higher compared to the others. This observation suggests a need for further analysis to understand the reasons behind this pricing difference.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "448CDAPjqfQr"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cspy4FjqxJW"
      },
      "source": [
        "**Positive Business Impact:**\n",
        "\n",
        "*The insights gained from the analysis can lead to a positive business impact in several ways:*\n",
        "\n",
        "**Targeted Marketing:** *Understanding that most bookings occur in the $800 to $1200 price range allows for more targeted marketing and promotions within this range, potentially increasing bookings and revenue.*\n",
        "\n",
        "**Agency Performance Analysis:** *Noting that FlyingDrops has a higher average price range can lead to a deeper understanding of what differentiates it from other agencies. This could be due to better service, more premium options, or a specific customer base. Leveraging these insights could help other agencies adjust their offerings or pricing strategies to capture a similar market.*\n",
        "\n",
        "**Pricing Strategy Optimization:** *The data can be used to refine pricing strategies, ensuring that prices are competitive yet profitable. Understanding the price sensitivity of customers can also inform discount strategies or bundled offers.*\n",
        "\n",
        "**Insights Leading to Negative Growth:**\n",
        "\n",
        "*While the insights themselves are neutral, their application could lead to negative growth if misinterpreted or mishandled. For example:*\n",
        "\n",
        "**Overpricing:** *If FlyingDrops higher prices are due to factors not related to customer preference (e.g., hidden fees, lack of alternatives), and other agencies increase prices to match without providing additional value, it could lead to a loss of customers to competitors or a decrease in overall bookings*.\n",
        "\n",
        "**Misalignment with Customer Expectations:** *If marketing efforts focus too heavily on the higher price range, they might alienate cost-sensitive customers or those looking for budget options, potentially reducing market share.*\n",
        "\n",
        "**Ignoring Underlying Factors:** *If the higher average prices at FlyingDrops are due to specific routes or peak travel times and these factors are not addressed or understood, applying a blanket strategy based on this data could lead to ineffective or counterproductive outcomes.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSlN3yHqYklG"
      },
      "source": [
        "#### Chart - 2 Pie chart"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7PBofO7oWu_W"
      },
      "outputs": [],
      "source": [
        "agency_counts = flights_df['agency'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M9vfPwNrWwu-"
      },
      "outputs": [],
      "source": [
        "agency_counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "outputs": [],
      "source": [
        "# Chart - 2 visualization code\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.pie(agency_counts, labels=agency_counts.index,autopct='%1.1f%%',  startangle=140,colors=plt.get_cmap('tab20').colors)\n",
        "plt.title('Percentage Share of Each Agency')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6dVpIINYklI"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aaW0BYyYklI"
      },
      "source": [
        "*I used a pie chart to display the market share distribution of each agency. A pie chart offers a clear visualization for comparing and understanding the proportion of market share held by each category or component.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijmpgYnKYklI"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSx9atu2YklI"
      },
      "source": [
        "*The chart reveals that Rainbow Agency holds the largest market share at around 42.9%, closely followed by Cloudy at 42.8%. FlyingDrops has the smallest market share at 14.3%. However, despite its lower market share, FlyingDrops has a higher average ticket price compared to the other agencies.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JiQyfWJYklI"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcBbebzrYklV"
      },
      "source": [
        "**Positive Business Impact:**\n",
        "\n",
        "**Pricing and Revenue Optimization:** *Understanding that FlyingDrops, despite having a smaller market share, commands higher average ticket prices, suggests that there might be a segment of customers willing to pay more for certain services or routes. This insight can help businesses optimize pricing strategies to maximize revenue.*\n",
        "\n",
        "**Market Positioning:** *The data showing Rainbow and Cloudy Agencies' significant market shares highlights their strong market presence. Businesses can leverage this information to strengthen partnerships, improve service offerings, or tailor marketing campaigns to consolidate their positions.*\n",
        "\n",
        "**Strategic Growth Opportunities:** *Identifying the potential in different market segments allows agencies to tailor their strategies, such as expanding service offerings or improving customer experiences, to capture a larger market share or increase profitability.*\n",
        "\n",
        "**Insights Leading to Negative Growth:**\n",
        "\n",
        "**Overpricing Risks:** *If agencies misinterpret the higher prices at FlyingDrops as a market norm rather than a unique value proposition, they may raise prices across the board without adding corresponding value. This could alienate price-sensitive customers, leading to a decrease in bookings.*\n",
        "\n",
        "**Neglecting Smaller Segments:** *Focusing solely on larger market players like Rainbow and Cloudy could lead to neglecting smaller yet profitable segments. If agencies ignore niche markets or specialized services, they might miss opportunities for growth and diversification.*\n",
        "\n",
        "**Misalignment of Services:** *If agencies attempt to emulate FlyingDrops' pricing strategy without understanding the specific reasons behind its higher prices (such as premium services, exclusive routes, etc.), they might misalign their services with customer expectations, leading to dissatisfaction and reduced customer loyalty.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Of9eVA-YrdM"
      },
      "source": [
        "#### Chart - 4 Box plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "outputs": [],
      "source": [
        "# Chart - 4 visualization code\n",
        "sns.catplot(y = \"price\", x = \"from\", data = flights_df.sort_values(\"price\", ascending = False), kind=\"box\", height = 4, aspect = 3)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iky9q4vBYrdO"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJRCwT6DYrdO"
      },
      "source": [
        "*I used a box plot to show the price distribution of flights from different airports. This visualization effectively illustrates the range and spread of flight ticket prices.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6T5p64dYrdO"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      },
      "source": [
        "*The analysis of the price distribution based on the 'from' column reveals that most flights are typically priced between $800 and $1200. However, tickets from Salvador are slightly higher, with a median price around $1100. In contrast, São Paulo shows a wider price spread, indicating either a higher volume of flights or greater price fluctuations from this airport.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-Ehk30pYrdP"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLNxxz7MYrdP"
      },
      "source": [
        "**Positive Business Impact:**\n",
        "\n",
        "**Pricing Strategy Refinement:** *Knowing that most flights are priced between $800 and $1200 allows for more strategic pricing. Agencies can optimize their pricing models to capture the bulk of the market within this range while adjusting prices from Salvador to reflect its higher median.*\n",
        "\n",
        "**Focused Marketing Campaigns:** *Targeting campaigns can be designed to cater to specific airports. For instance, highlighting deals or promotions from São Paulo can attract more travelers if there is high traffic and price fluctuation.*\n",
        "\n",
        "**Resource Allocation**: *Insights into higher prices from Salvador and the wider spread from São Paulo can help in better resource allocation. Agencies can ensure that they provide adequate services and support at these airports to enhance customer satisfaction and capitalize on the pricing trends.*\n",
        "\n",
        "**Insights Leading to Negative Growth:**\n",
        "\n",
        "**Mispricing Risks:** *Overgeneralizing the price insights might lead to mispricing. For example, increasing prices at other airports to match Salvadors higher median without adding value could drive customers away.*\n",
        "\n",
        "**Ignoring Specific Market Needs:** *If the focus is solely on average price ranges, agencies might overlook the specific needs and behaviors of travelers from different airports. This could result in a one-size-fits-all approach that doesn’t cater to unique market segments, reducing customer satisfaction.*\n",
        "\n",
        "**Price Sensitivity:** *If agencies assume that the wider price spread from São Paulo indicates willingness to pay higher prices without understanding underlying factors (e.g., demand variability, economic conditions), they might set prices too high, causing a drop in bookings.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bamQiAODYuh1"
      },
      "source": [
        "#### Chart - 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "outputs": [],
      "source": [
        "# Chart - 5 visualization code\n",
        "sns.catplot(y = \"price\", x = \"to\", data = flights_df.sort_values(\"price\", ascending = False), kind=\"box\", height = 4, aspect = 3)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcxuIMRPYuh3"
      },
      "source": [
        "*I used a box plot to analyze the price distribution across different destination airports. This visualization helps us understand the spread of ticket prices and highlights the median price for each airport.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwzvFGzlYuh3"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyqkiB8YYuh3"
      },
      "source": [
        "*The box plot clearly shows that ticket prices vary across different destination airports. Salvador stands out with higher ticket prices, having a median around $1300 and reaching up to $1800, possibly due to high demand or limited flight availability. Conversely, São Paulo has a narrower price spread, with most ticket prices ranging between $600 and $800, which could be attributed to lower demand or a greater number of flight options.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYpmQ266Yuh3"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      },
      "source": [
        "**Positive Business Impact:**\n",
        "\n",
        "**Demand-Driven Pricing:** *Understanding that Salvador has higher ticket prices due to potential high demand or limited flights allows for dynamic pricing strategies. Agencies can adjust prices based on demand, optimizing revenue while ensuring flights to high-demand destinations are profitable.*\n",
        "\n",
        "**Service Expansion:** *Identifying the high demand for Salvador could justify increasing the number of flights or improving services to this destination. This can enhance customer satisfaction and capture more market share.*\n",
        "\n",
        "**Market Segmentation:** *The data on Sao Paulos lower price range can help tailor marketing efforts to price-sensitive travelers or promote more competitive pricing strategies to attract budget-conscious customers.*\n",
        "\n",
        "**Insights Leading to Negative Growth:**\n",
        "\n",
        "**Overpricing Risks:** *If agencies increase prices for destinations like Sao Paulo based on the insights from Salvador without considering demand elasticity, they might drive away cost-sensitive customers, leading to reduced bookings.*\n",
        "\n",
        "**Misallocation of Resources:** *Overemphasizing high-demand destinations like Salvador might lead to neglecting other potentially profitable routes. This could result in missed opportunities and imbalanced resource allocation.*\n",
        "\n",
        "**Customer Dissatisfaction:** *If price increases are perceived as unjustified or opportunistic, it could lead to customer dissatisfaction and damage the agency’s reputation, potentially causing a loss of customer loyalty and negative word-of-mouth.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OH-pJp9IphqM"
      },
      "source": [
        "#### Chart - 6 pie chart"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HueyzOPduofX"
      },
      "outputs": [],
      "source": [
        "type_count=flights_df['flightType'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iit7DR9_usv4"
      },
      "outputs": [],
      "source": [
        "type_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "outputs": [],
      "source": [
        "# Chart - 6 visualization code\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.pie(type_count, labels=type_count.index,autopct='%1.1f%%',  startangle=140,colors=plt.get_cmap('tab20').colors)\n",
        "plt.title('Percentage Share of Each Flight seat type')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbFf2-_FphqN"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loh7H2nzphqN"
      },
      "source": [
        "*I used a pie chart to display the percentage share of different flight types. This chart provides a clear and comprehensive visualization of the proportion each flight type represents within the overall dataset.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ouA3fa0phqN"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VECbqPI7phqN"
      },
      "source": [
        "*The pie chart reveals that the dataset includes three flight types: first class, premium, and economy. The highest percentage share is first class at around 42%, followed by premium at 28.7%, and economy at 28.5%. This insight indicates a preference for first class tickets among travelers.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Seke61FWphqN"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvSq8iUTphqO"
      },
      "source": [
        "**Positive Business Impact:**\n",
        "\n",
        "**Premium Service Focus:** *Knowing that first class has the highest share suggests a strong market for premium services. Agencies can capitalize on this by enhancing their first-class offerings, promoting luxury features, and targeting marketing efforts to affluent travelers.*\n",
        "\n",
        "**Revenue Optimization:** *Emphasizing first class, which typically generates higher revenue per ticket, can boost overall profitability. Agencies can structure pricing strategies and flight schedules to maximize the availability and appeal of first-class options.*\n",
        "\n",
        "**Customer Segmentation:** *The insights allow for better customer segmentation. By understanding the distribution of preferences, agencies can tailor their services and communications to different segments, improving customer satisfaction and loyalty.*\n",
        "\n",
        "**Insights Leading to Negative Growth:**\n",
        "\n",
        "**Overinvestment in Premium Services:** *Focusing too heavily on first-class services at the expense of economy and premium options might alienate cost-conscious travelers, potentially reducing the overall customer base.*\n",
        "\n",
        "**Mispricing Risk:** *Assuming a uniform preference for first class could lead to price hikes across the board. If not carefully managed, this might price out a significant portion of travelers who prefer economy or premium options, leading to a drop in bookings.*\n",
        "\n",
        "**Ignoring Economic Fluctuations:** *The current preference for first class might change with economic conditions. If agencies invest heavily based on current data without considering potential market shifts, they could face reduced demand during economic downturns.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIIx-8_IphqN"
      },
      "source": [
        "#### Chart - 7 Box Plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "outputs": [],
      "source": [
        "# Chart - 7 visualization code\n",
        "sns.catplot(y = \"price\", x = \"flightType\", data = flights_df.sort_values(\"price\", ascending = False), kind=\"box\", height = 4, aspect = 3)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t27r6nlMphqO"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iv6ro40sphqO"
      },
      "source": [
        "*I used a box plot to analyze and compare prices across different flight types. This visualization provides a detailed comparison of price distributions both between and within each flight type.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2jJGEOYphqO"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Po6ZPi4hphqO"
      },
      "source": [
        "*The box plot reveals distinct price ranges for each flight type. First class has the highest prices, ranging from \\$600 to \\$1800, with a median price around \\$1200. Premium flights range from \\$500 to \\$1400, with a median of \\$900. Economy flights, the least expensive, range from \\$300 to \\$1000, with a median of \\$700. This price analysis enhances our understanding of customer behavior and spending patterns on flight bookings.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0JNsNcRphqO"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Positive Business Impact:**\n",
        "\n",
        "**Targeted Marketing and Promotions:** *Understanding the price ranges and median prices for each flight type allows for more effective marketing strategies. Agencies can tailor promotions and advertising to highlight the value of each flight type, targeting customers based on their spending patterns.*\n",
        "\n",
        "**Revenue Management:** *The insights help in optimizing pricing strategies. Knowing that first-class tickets command the highest prices, agencies can adjust inventory and pricing dynamically to maximize revenue, especially during peak travel times.*\n",
        "\n",
        "**Customer Segmentation:** *The analysis provides a clear picture of how different customer segments are spending on flights. This enables agencies to offer personalized services and packages that cater to the needs and preferences of each segment, improving customer satisfaction and loyalty.*\n",
        "\n",
        "**Insights Leading to Negative Growth**:\n",
        "\n",
        "**Overemphasis on High-Priced Tickets:** *If agencies focus too heavily on promoting first-class and premium tickets, they may neglect the economy segment, which could lead to a decline in overall bookings from cost-sensitive travelers.*\n",
        "\n",
        "**Price Sensitivity:** *Raising prices across the board based on the high median prices in first class and premium categories could alienate budget-conscious customers. This might result in a decrease in bookings and a potential loss of market share to competitors.*\n",
        "\n",
        "**Ignoring Market Fluctuations:** *The current price analysis might not account for seasonal variations or economic downturns. If agencies base their strategies solely on these insights without considering market changes, they might face challenges in maintaining profitability during low-demand periods.*"
      ],
      "metadata": {
        "id": "sHJjwGBNoSfN"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZR9WyysphqO"
      },
      "source": [
        "#### Chart - 8 Distplot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "outputs": [],
      "source": [
        "# Chart - 8 visualization code\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.distplot(flights_df['price'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jj7wYXLtphqO"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ob8u6rCTphqO"
      },
      "source": [
        "*I used a distplot to showcase the price distributions and density. This provides a comprehensive view of how prices are distributed across the dataset.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZrbJ2SmphqO"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZtgC_hjphqO"
      },
      "source": [
        "*The distplot provides insights into price distribution, revealing that most people book flight tickets priced between $600 and $900. This helps us understand typical spending patterns on flight bookings.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFu4xreNphqO"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ey_0qi68phqO"
      },
      "source": [
        "**Positive Business Impact:**\n",
        "\n",
        "**Pricing Strategy Optimization:** *Knowing that most bookings fall between $600 and $900 allows airlines to optimize their pricing strategies to target this range, potentially increasing bookings and revenue.*\n",
        "\n",
        "**Targeted Promotions:** *Marketing campaigns can focus on the $600 to $900 price range, offering promotions and discounts within this range to attract more customers.*\n",
        "\n",
        "**Inventory Management:** *Airlines can better manage their inventory by ensuring that a significant number of tickets are available within the $600 to $900 range, aligning with customer spending habits.*\n",
        "\n",
        "**Customer Insights:** *Understanding customer spending patterns helps airlines tailor their services and packages to meet customer expectations, enhancing satisfaction and loyalty.*\n",
        "\n",
        "**Insights Leading to Negative Growth:**\n",
        "\n",
        "**Overemphasis on Mid-Range Pricing:** *Focusing too heavily on the $600 to $900 price range might lead to neglecting other customer segments, such as those willing to pay more for premium services or those looking for budget options. This could result in a loss of potential revenue from these segments*.\n",
        "\n",
        "**Price Rigidity:** *If airlines become too rigid in their pricing strategies based on this data, they may miss opportunities to adjust prices dynamically in response to market fluctuations, potentially leading to reduced competitiveness and decreased bookings.*\n",
        "\n",
        "**Ignoring External Factors:** *The current spending patterns might be influenced by specific market conditions or seasonal trends. If airlines base their long-term strategies solely on these insights without considering broader market dynamics, they might face challenges in adapting to changes in customer behavior or economic conditions.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJ55k-q6phqO"
      },
      "source": [
        "#### Chart - 9 Distplot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mtXD5-5iypNT"
      },
      "outputs": [],
      "source": [
        "flights_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "outputs": [],
      "source": [
        "# Chart - 9 visualization code\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.distplot(flights_df['total_time'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCFgpxoyphqP"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVxDimi2phqP"
      },
      "source": [
        "*I used a distplot to visualize the total flight time and its density within the dataset. This provides a clear view of the distribution of total flight times and their density.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVtJsKN_phqQ"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngGi97qjphqQ"
      },
      "source": [
        "*The visualization reveals that flight times in the dataset are approximately normally distributed. It shows that while people take both short and long flights, longer flights (over 120 minutes) are more frequent than shorter ones.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lssrdh5qphqQ"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBpY5ekJphqQ"
      },
      "source": [
        "**Positive Business Impact:**\n",
        "\n",
        "**Service Optimization:** *Understanding that longer flights (over 120 minutes) are more frequent can help airlines optimize their services, such as providing additional amenities, catering, and in-flight entertainment, to enhance the customer experience for longer journeys.*\n",
        "\n",
        "**Flight Scheduling:** *Airlines can use this insight to better schedule flights and allocate resources. Knowing that longer flights are more common can lead to more efficient use of aircraft and crew, improving operational efficiency.*\n",
        "\n",
        "**Targeted Marketing:** *With the knowledge that longer flights are more frequent, airlines can tailor their marketing efforts to emphasize the value and comfort of their long-haul services, potentially attracting more customers for these flights.*\n",
        "\n",
        "**Insights Leading to Negative Growth:**\n",
        "\n",
        "**Overlooking Short Flights:** *Focusing solely on longer flights might lead to neglecting the needs of customers who prefer shorter trips. This could result in reduced satisfaction and lost revenue from the short-haul market.*\n",
        "\n",
        "**Resource Allocation:** *If airlines overinvest in services or amenities for longer flights at the expense of short-haul flights, they might face inefficiencies or customer dissatisfaction in their short-haul services.*\n",
        "\n",
        "**Price Adjustments:** *If the focus shifts disproportionately toward long-haul flights based on their frequency, there might be pressure to adjust pricing strategies that could alienate budget-conscious customers who prefer shorter, less expensive flights.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      },
      "source": [
        "#### Chart - 10 Bar chart"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IIYv-XnqpSAB"
      },
      "outputs": [],
      "source": [
        "flights_df['distance'].max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vh3pUScmpHzy"
      },
      "outputs": [],
      "source": [
        "flights_df.distance.groupby(pd.cut(flights_df.distance, np.arange(0,1000,100))).count().plot(kind='barh',figsize = (20,6))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "outputs": [],
      "source": [
        "# Chart - 10 visualization code\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.distplot(flights_df['distance'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1M8mcRywphqQ"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8agQvks0phqQ"
      },
      "source": [
        "*I used a bar chart and distplot to display the flight distances and their distribution. This provides insights into how frequently flights occur at various distance ranges.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgIPom80phqQ"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qp13pnNzphqQ"
      },
      "source": [
        "*The bar chart indicates that flights in the dataset cover distances ranging from 100 to 900 miles (or kilometers). Most flights are between 500 and 700 miles, while the fewest are in the 300 to 400-mile range. This insight is also reflected in the distplot, which shows that the highest density of flights occurs within the 500 to 700-mile distance range.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMzcOPDDphqR"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4Ka1PC2phqR"
      },
      "source": [
        "**Positive Business Impact:**\n",
        "\n",
        "**Route Optimization:** *Understanding that most flights fall within the 500 to 700-mile range can help airlines optimize their route networks and schedules to focus on high-demand distances. This can improve operational efficiency and increase profitability.*\n",
        "\n",
        "**Targeted Marketing:** *Airlines can tailor marketing strategies to emphasize their most frequently flown routes, potentially increasing bookings and customer engagement for these distances.*\n",
        "\n",
        "**Resource Allocation:** *Knowing the common flight distances allows airlines to allocate resources more effectively, such as customizing aircraft configurations and crew assignments to suit the predominant flight lengths.*\n",
        "\n",
        "**Insights Leading to Negative Growth:**\n",
        "\n",
        "**Neglecting Other Routes:** *A focus solely on the 500 to 700-mile range might lead to the neglect of shorter or longer routes. This could result in missed opportunities and reduced revenue from other potential markets.*\n",
        "\n",
        "**Overcapacity Risks:** *If airlines overemphasize flights within the 500 to 700-mile range, there is a risk of overcapacity on these routes, which could lead to reduced profitability due to increased competition or lower ticket prices.*\n",
        "\n",
        "**Misaligned Service Offerings:** *If airlines adjust their service offerings based on the most common flight distances, they might not cater effectively to customers who prefer shorter or longer flights, potentially reducing customer satisfaction and loyalty.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-EpHcCOp1ci"
      },
      "source": [
        "#### Chart - 11 Scatter Plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mAQTIvtqp1cj"
      },
      "outputs": [],
      "source": [
        "# Chart - 11 visualization code\n",
        "# Create a scatter plot\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.scatterplot(x=\"price\", y=\"distance\", data=flights_df)\n",
        "plt.xlabel(\"Price\")\n",
        "plt.ylabel(\"Distance\")\n",
        "plt.title(\"Price vs Distance Scatter Plot\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_VqEhTip1ck"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vsMzt_np1ck"
      },
      "source": [
        "*I used a scatter plot to examine the correlation between price and distance. This visualization provides a comprehensive view of how these two variables are related.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zGJKyg5p1ck"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYdMsrqVp1ck"
      },
      "source": [
        "*The scatter plot reveals a positive correlation between price and distance, indicating that as the distance of a flight increases, the ticket price tends to rise. However, some shorter flights have higher prices, which may be due to factors such as ticket type or flight class, with 42% of flights being first class, as noted earlier.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVzmfK_Ep1ck"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "druuKYZpp1ck"
      },
      "source": [
        "**Positive Business Impact:**\n",
        "\n",
        "**Pricing Strategy Optimization:** *Understanding the positive correlation between price and distance helps airlines refine their pricing strategies. Airlines can adjust prices based on distance to better align with customer expectations and maximize revenue.*\n",
        "\n",
        "**Revenue Management:** *Insights into how distance affects ticket prices can assist in managing revenue by setting appropriate price points for different flight lengths, improving overall profitability.*\n",
        "\n",
        "**Targeted Offers:** *Recognizing that some shorter flights have high prices, airlines can tailor their marketing and promotional offers to highlight the value of longer flights or offer competitive pricing on shorter flights to attract more customers.*\n",
        "\n",
        "**Insights Leading to Negative Growth:**\n",
        "\n",
        "**Price Sensitivity:** *If airlines overly focus on distance-based pricing without considering other factors, such as ticket type or customer preferences, they may alienate price-sensitive travelers, potentially reducing bookings.*\n",
        "\n",
        "**Mispricing Risks:** *Shorter flights with higher prices due to ticket type or class could lead to perceived unfair pricing. If not managed well, this could result in customer dissatisfaction and lost revenue from potential customers seeking better value.*\n",
        "\n",
        "**Market Overemphasis:** *A focus on distance-based pricing might lead to neglecting other important factors, such as flight quality or customer service, which can affect overall customer satisfaction and loyalty.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3dbpmDWp1ck"
      },
      "source": [
        "#### Chart - 12 Bar chart"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nJgLsYiDOdS9"
      },
      "outputs": [],
      "source": [
        "flights_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6rykc35aecPc"
      },
      "outputs": [],
      "source": [
        "flights_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bwevp1tKp1ck"
      },
      "outputs": [],
      "source": [
        "# Chart - 12 visualization code\n",
        "plt.figure(figsize = (10, 5))\n",
        "plt.title('Count of flights month wise')\n",
        "ax=sns.countplot(x = 'month', data = flights_df)\n",
        "plt.xlabel('Month')\n",
        "plt.ylabel('Count of flights')\n",
        "for p in ax.patches:\n",
        "    ax.annotate(int(p.get_height()), (p.get_x()+0.25, p.get_height()+1), va='bottom', color= 'black')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Ue7DYrgPjHy"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 7))\n",
        "sns.distplot(flights_df['month'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylSl6qgtp1ck"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2xqNkiQp1ck"
      },
      "source": [
        "*I used a bar chart to display the number of flights each month and the distplot to visualize the distribution the total flights over a month.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWILFDl5p1ck"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-lUsV2mp1ck"
      },
      "source": [
        "*The bar chart reveals a clear trend in flight frequency over the months. It shows that flights are more frequent in October, November, and December, likely due to the festive season, while August has notably fewer flights.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7G43BXep1ck"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wwDJXsLp1cl"
      },
      "source": [
        "\n",
        "**Positive Business Impact:**\n",
        "\n",
        "**Seasonal Planning:** *Recognizing the increased flight frequency in October, November, and December allows airlines to plan and allocate resources effectively for the busy festive season. This can help optimize staffing, manage capacity, and improve customer service during peak travel periods.*\n",
        "\n",
        "**Targeted Marketing:** *The insight into higher flight activity during the last months of the year can be used to design targeted marketing campaigns and promotions. Airlines can capitalize on the festive season by offering special deals or incentives to attract more travelers.*\n",
        "\n",
        "**Revenue Optimization:** *Understanding the seasonal trends can help airlines adjust pricing strategies dynamically. They can implement higher fares during peak months to maximize revenue and offer discounts during quieter periods like August to stimulate demand.*\n",
        "\n",
        "**Insights Leading to Negative Growth:**\n",
        "\n",
        "**Overlooking Low Season Demand:** *If airlines focus only on the busy months and ignore the lower demand in August, they may miss opportunities to attract more travelers during off-peak times. This could lead to underutilization of capacity and reduced revenue.*\n",
        "\n",
        "**Resource Misallocation:** *Excessive focus on peak months might lead to overinvestment in resources for those periods, potentially causing inefficiencies and higher operational costs. Conversely, insufficient attention to quieter months could result in missed revenue opportunities.*\n",
        "\n",
        "**Customer Perception:** *If pricing is adjusted based on peak season insights without considering customer sensitivity, it could lead to perceptions of unfair pricing or reduced customer satisfaction, particularly during off-peak times.*\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ag9LCva-p1cl"
      },
      "source": [
        "#### Chart - 13 Distplot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EUfxeq9-p1cl"
      },
      "outputs": [],
      "source": [
        "# Chart - 13 visualization code\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.distplot(flights_df['weekday_num'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6MkPsBcp1cl"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V22bRsFWp1cl"
      },
      "source": [
        "*I used a distplot to visualize the count of flights on different weekdays, providing a density distribution of flights throughout the week.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cELzS2fp1cl"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozQPc2_Ip1cl"
      },
      "source": [
        "*The distplot reveals that the majority of flights operate on Thursday, while there are no flights running on Tuesday and Wednesday.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MPXvC8up1cl"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GL8l1tdLp1cl"
      },
      "source": [
        "**Positive Business Impact:**\n",
        "\n",
        "**Optimized Scheduling:** *Understanding that most flights operate on Thursday can help airlines optimize their scheduling, ensuring adequate resources and staffing on high-demand days to improve efficiency and customer service.*\n",
        "\n",
        "**Promotional Strategies:** *Airlines can use this insight to develop targeted promotional campaigns to boost bookings on low-demand days like Tuesday and Wednesday, potentially increasing overall flight utilization and revenue.*\n",
        "\n",
        "**Resource Allocation:** *Airlines can allocate resources more effectively by concentrating on maintenance and training activities on days with fewer or no flights, thereby minimizing disruptions to operations.*\n",
        "\n",
        "**Insights Leading to Negative Growth:**\n",
        "\n",
        "**Capacity Imbalance:** *If airlines focus too heavily on Thursday operations without addressing the low activity on Tuesday and Wednesday, they may face capacity imbalances, leading to overcrowded flights on Thursdays and underutilized capacity on other days.*\n",
        "\n",
        "**Customer Inconvenience:** *Limited flight options on Tuesday and Wednesday might inconvenience travelers who prefer to fly on those days, potentially driving them to choose competitors with more balanced schedules.*\n",
        "\n",
        "**Missed Revenue Opportunities:** *By not offering flights on Tuesday and Wednesday, airlines might miss out on potential revenue from customers who need to travel on those days, leading to reduced overall profitability.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NC_X3p0fY2L0"
      },
      "source": [
        "#### Chart - 14 - Correlation Heatmap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_uXTj7GSgIlN"
      },
      "outputs": [],
      "source": [
        "columns_to_drop = ['time', 'date']\n",
        "flights_df1 = flights_df.drop(columns=columns_to_drop)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4MMVzFyxc-dA"
      },
      "outputs": [],
      "source": [
        "flights_df1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XKEsiYOpROcD"
      },
      "outputs": [],
      "source": [
        "flights_df1.corr(numeric_only=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MrDbJ5EvZ91b"
      },
      "outputs": [],
      "source": [
        "f,ax = plt.subplots(figsize=(10,10))\n",
        "sns.heatmap(abs(round(flights_df1.corr(numeric_only=True),3)), annot=True, linewidths=.5, fmt= '.1f',ax=ax)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      },
      "source": [
        "*I used a correlation heatmap for all variables to gain insights into their relationships and their impact on the target variable. The heatmap provides a comprehensive visualization with color coding and correlation values, making it easy to understand variable correlations and identify multicollinearity.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfSqtnDqZNRR"
      },
      "source": [
        "*The heatmap reveals that our target variable, flight price, has a positive correlation with variables such as total time, distance, and speed. User code and flight code show only minor correlation. Additionally, distance and total time are highly correlated, indicating multicollinearity, meaning they provide similar information regarding the target variable.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q29F0dvdveiT"
      },
      "source": [
        "#### Chart - 15 - Pair Plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "outputs": [],
      "source": [
        "# Pair Plot visualization code\n",
        "plt.figure(figsize=(10, 10))\n",
        "sns.pairplot(flights_df1)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXh0U9oCveiU"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMmPjTByveiU"
      },
      "source": [
        "*I used a pairplot to analyze the relationships between variables. This visualization provides easy-to-understand insights into how each variable relates to the others.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22aHeOlLveiV"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPQ8RGwHveiV"
      },
      "source": [
        "*Most variables in our dataset are discrete in nature. The pairplot reveals that speed and distance have a strong negative correlation, while time and distance show a positive correlation. Additionally, the pairplot provides insights into the skewness of the variables, showing that most of them are normally distributed.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-ATYxFrGrvw"
      },
      "source": [
        "## ***5. Hypothesis Testing***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      },
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7MS06SUHkB-"
      },
      "source": [
        "Hypothetical Statement - 1 The average flight price is greater than $200.\n",
        "\n",
        "Hypothetical Statement - 2 The average flight duration is different for flights above and below 600 km.\n",
        "\n",
        "Hypothetical Statement - 3 correlation between flight price and distance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7VLkx3UxIeh1"
      },
      "outputs": [],
      "source": [
        "flights_df1.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yEUt7NnHlrM"
      },
      "source": [
        "### Hypothetical Statement - 1 The average flight price is greater than $200."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      },
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HI9ZP0laH0D-"
      },
      "source": [
        "**Null Hypothesis (H0): The average flight price is less than or equal to $200.**\n",
        "\n",
        "**Alternative Hypothesis (H1): The average flight price is greater than $200.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I79__PHVH19G"
      },
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPP8FP4ONUUc"
      },
      "source": [
        "**One-sample t-test: Is the average flight price > $200?**\n",
        "\n",
        "**Null Hypothesis (H0): μ <= 200**\n",
        "\n",
        "**Alternative Hypothesis (H1): μ > 200**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "outputs": [],
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "\n",
        "mu = 200\n",
        "t_stat, p_value = stats.ttest_1samp(flights_df1['price'], mu)\n",
        "print(f\"T-statistic: {t_stat}, P-value: {p_value/2}\")\n",
        "\n",
        "if p_value/2 < 0.05:\n",
        "    print(\"Reject the null hypothesis. The average flight price is greater than $200.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ou-I18pAyIpj"
      },
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2U0kk00ygSB"
      },
      "source": [
        "*The statistical test performed is a one-sample t-test, also known as a one-sample t-test or single-sample t-test.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fF3858GYyt-u"
      },
      "source": [
        "##### Why did you choose the specific statistical test?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HO4K0gP5y3B4"
      },
      "source": [
        "*I chose to perform a one-sample t-test because it is specifically designed to compare the mean of a sample to a hypothesized value, which aligns with my goal of testing whether the average flight price exceeds $200.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_0_7-oCpUZd"
      },
      "source": [
        "### Hypothetical Statement - 2 The average flight duration is different for flights above and below 600 km."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwyV_J3ipUZe"
      },
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      },
      "source": [
        "**Null Hypothesis (H0): The average flight duration is the same for flights above and below 600 km.**\n",
        "\n",
        "**Alternative Hypothesis (H1): The average flight duration is different for flights above and below 600 km.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yB-zSqbpUZe"
      },
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hg_NHqDnNibE"
      },
      "source": [
        "**Two-sample t-test: Is the average time different for flights above and below 600 km?**\n",
        "\n",
        "**Null Hypothesis (H0): μ_above = μ_below**\n",
        "\n",
        "**Alternative Hypothesis (H1): μ_above ≠ μ_below**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "outputs": [],
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "\n",
        "above_600 = flights_df1[flights_df1['distance'] > 600]['total_time']\n",
        "below_600 = flights_df1[flights_df1['distance'] <= 600]['total_time']\n",
        "\n",
        "t_stat, p_value = stats.ttest_ind(above_600, below_600)\n",
        "print(f\"T-statistic: {t_stat}, P-value: {p_value}\")\n",
        "\n",
        "if p_value < 0.05:\n",
        "    print(\"Reject the null hypothesis. The average flight duration is different for flights above and below 600 km.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEUvejAfpUZe"
      },
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLDrPz7HpUZf"
      },
      "source": [
        "*I used a two-sample t-test to compare the time differences between flights with distances greater than 600 km and those with distances less than 600 km.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fd15vwWVpUZf"
      },
      "source": [
        "##### Why did you choose the specific statistical test?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xOGYyiBpUZf"
      },
      "source": [
        "*I chose the two-sample t-test because it is designed to compare the means of two independent samples, which aligns with my hypothesis of comparing flight times for distances above and below 600 km.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bn_IUdTipZyH"
      },
      "source": [
        "### Hypothetical Statement - 3 correlation between flight price and distance\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49K5P_iCpZyH"
      },
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gWI5rT9pZyH"
      },
      "source": [
        "**Null Hypothesis (H0): There is no correlation between flight price and distance (correlation coefficient = 0).**\n",
        "\n",
        "**Alternative Hypothesis (H1): There is a correlation between flight price and distance (correlation coefficient ≠ 0).**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nff-vKELpZyI"
      },
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5G6ci70NwV2"
      },
      "source": [
        "**Pearson correlation test: Is there a correlation between price and distance?**\n",
        "\n",
        "**Null Hypothesis (H0): ρ = 0**\n",
        "\n",
        "**Alternative Hypothesis (H1): ρ ≠ 0**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "outputs": [],
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "\n",
        "correlation, p_value = stats.pearsonr(flights_df1['price'], flights_df1['distance'])\n",
        "print(f\"Correlation: {correlation}, P-value: {p_value}\")\n",
        "\n",
        "if p_value < 0.05:\n",
        "    print(\"Reject the null hypothesis. There is a correlation between flight price and distance.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLW572S8pZyI"
      },
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytWJ8v15pZyI"
      },
      "source": [
        "*I used the Pearson correlation test to assess the correlation between price and distance, as part of testing the hypothesis regarding their relationship.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWbDXHzopZyI"
      },
      "source": [
        "##### Why did you choose the specific statistical test?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M99G98V6pZyI"
      },
      "source": [
        "*I used the Pearson correlation test because it is designed to evaluate the relationship between two variables, which aligns with my goal of examining the correlation between price and distance.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLjJCtPM0KBk"
      },
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xiyOF9F70UgQ"
      },
      "source": [
        "### 1. Handling Missing Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "outputs": [],
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "flights_df1.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wuGOrhz0itI"
      },
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ixusLtI0pqI"
      },
      "source": [
        "*There are no null values in our dataset*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "id1riN9m0vUs"
      },
      "source": [
        "### 2. Handling Outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "outputs": [],
      "source": [
        "# Handling Outliers & Outlier treatments\n",
        "flights_df1.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jgp7VvGiP3PP"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "plt.title(\"Box plot of distance \")\n",
        "ax = sns.boxplot(data=flights_df1['distance'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "578E2V7j08f6"
      },
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGZz5OrT1HH-"
      },
      "source": [
        "*I used a box plot to visualize the spread of distances and detect outliers. The analysis revealed that there are no significant outliers that require treatment.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ODbU--YLQVRs"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "plt.title(\"Box plot of total time taken\")\n",
        "ax = sns.boxplot(data=flights_df1['total_time'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used a box plot to visualize the spread of time and detect outliers. The analysis revealed that there are no significant outliers that require treatment."
      ],
      "metadata": {
        "id": "-1cMUjlFPHLN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mHMU03isQfwl"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "plt.title(\"Box plot of speed\")\n",
        "ax = sns.boxplot(data=flights_df1['speed'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used a box plot to visualize the spread of speed and detect outliers. The analysis revealed that there are no significant outliers that require treatment."
      ],
      "metadata": {
        "id": "KPZLjJ9rPMUr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q5uCQ6xeQ_LB"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "plt.title(\"Box plot of price\")\n",
        "ax = sns.boxplot(data=flights_df1['price'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used a box plot to visualize the price of distances and detect outliers. The analysis revealed that there are no significant outliers that require treatment."
      ],
      "metadata": {
        "id": "y1qVcNTyPOtY"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89xtkJwZ18nB"
      },
      "source": [
        "### 3. Categorical Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "outputs": [],
      "source": [
        "# Encode your categorical columns\n",
        "categorical_data = flights_df1.select_dtypes(exclude=['int64', 'float','int32'])\n",
        "numerical_data = flights_df1.select_dtypes(include=['int64', 'float','int32'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_z_QUSg4Smc6"
      },
      "outputs": [],
      "source": [
        "categorical_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hGvCWia7SqKQ"
      },
      "outputs": [],
      "source": [
        "numerical_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9YZqC0cPStFM"
      },
      "outputs": [],
      "source": [
        "le = LabelEncoder()\n",
        "categorical_data = categorical_data.apply(LabelEncoder().fit_transform)\n",
        "categorical_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "# Save the LabelEncoder to a file\n",
        "joblib.dump(le, '/content/label.pkl')\n"
      ],
      "metadata": {
        "id": "K9MhxbuTBApb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67NQN5KX2AMe"
      },
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDaue5h32n_G"
      },
      "source": [
        "*I used label encoding for categorical variables because it converts categorical values into numerical values, which is necessary for many machine learning algorithms that require numerical input.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XbyhmWzsTGQ0"
      },
      "outputs": [],
      "source": [
        "encode_df= pd.concat([categorical_data,numerical_data], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ztdyS5IATQ0L"
      },
      "outputs": [],
      "source": [
        "encode_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "up0Q_tw4TpA3"
      },
      "outputs": [],
      "source": [
        "encode_df.drop(['weekday'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RjwDpffFT4iL"
      },
      "outputs": [],
      "source": [
        "encode_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      },
      "source": [
        "### 4. Feature Manipulation & Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C74aWNz2AliB"
      },
      "source": [
        "#### 1. Feature Manipulation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*I have already completed feature manipulation during the data wrangling phase.*"
      ],
      "metadata": {
        "id": "XTWipwQTPs3E"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DejudWSA-a0"
      },
      "source": [
        "#### 2. Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YLhe8UmaBCEE"
      },
      "outputs": [],
      "source": [
        "# Select your features wisely to avoid overfitting\n",
        "\n",
        "for col in encode_df.describe().columns.tolist():\n",
        "    fig = plt.figure(figsize=(20, 6))\n",
        "    ax = fig.gca()\n",
        "    feature = encode_df[col]\n",
        "    label = encode_df['price']\n",
        "    correlation = feature.corr(label)\n",
        "    sns.scatterplot(x=feature, y=label, color=\"gray\")\n",
        "    plt.xlabel(col)\n",
        "    plt.ylabel('price')\n",
        "    ax.set_title('price vs ' + col + '- correlation: ' + str(correlation))\n",
        "    z = np.polyfit(encode_df[col], encode_df['price'], 1)\n",
        "    y_hat = np.poly1d(z)(encode_df[col])\n",
        "    plt.plot(encode_df[col], y_hat, \"r--\", lw=1)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eujBEl0ZWJn1"
      },
      "outputs": [],
      "source": [
        "encode_df.corr()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q7aNrmxqVwCY"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15,15))\n",
        "sns.heatmap(abs(round(encode_df.corr(),3)), annot=True, cmap=plt.cm.CMRmap)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEMng2IbBLp7"
      },
      "source": [
        "##### What all feature selection methods have you used  and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rb2Lh6Z8BgGs"
      },
      "source": [
        "* We have used scatter plot to check how each variable is affecting on target variable.\n",
        "\n",
        "* Correlation Matrix(Heatmap): A correlation matrix can be used to select features that have high correlations with the target variable and low correlations with other features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAdphbQ9Bhjc"
      },
      "source": [
        "##### Which all features you found important and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGgaEstsBnaf"
      },
      "source": [
        "**Important Features:**\n",
        "\n",
        "* Distance (distance): Correlation with price is 0.6419. This strong positive correlation indicates that as the distance increases, the price tends to increase.\n",
        "\n",
        "* Total Time (total_time): Correlation with price is 0.6310. Similar to distance, total time also shows a strong positive correlation with the price.\n",
        "\n",
        "* Speed (speed): Correlation with price is 0.4187. This moderate positive correlation suggests that speed also has an impact on the price.\n",
        "\n",
        "These features are likely important for the model because they show a significant correlation with the target variable, price.\n",
        "\n",
        "**Potentially Less Important Features:**\n",
        "\n",
        "* Agency (agency): Correlation with price is very low (0.000974). This suggests that the choice of agency does not significantly affect the price in this dataset.\n",
        "\n",
        "* Route (route): Correlation with price is also low (0.017137). Similar to agency, route does not seem to have a significant impact on the price.\n",
        "\n",
        "* Month (month): Correlation with price is almost zero (-0.000013), indicating little to no linear relationship with the price.\n",
        "\n",
        "These features may be less impactful for the model as they show little to no correlation with the target variable.\n",
        "\n",
        "**Multicollinearity Concerns:**\n",
        "\n",
        "* TravelCode and UserCode: These features are highly correlated with each other (correlation ~1) and have similar correlations with the target variable.\n",
        "\n",
        "* Distance and Total Time: High correlation (0.9552) between these features suggests that they might be capturing similar information."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Optional:**\n",
        "\n",
        "***Checking the other dataset variables to identify any underlying patterns or correlations with our target variable.***"
      ],
      "metadata": {
        "id": "_hGK5FioQM0Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sSNm9nKXAfkH"
      },
      "outputs": [],
      "source": [
        "users_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1MnMq6FKArMo"
      },
      "outputs": [],
      "source": [
        "flights_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MHpvU7AZ_83z"
      },
      "outputs": [],
      "source": [
        "con_data=pd.merge(flights_df,users_df,how='left',left_on='userCode',right_on='code')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EL54quAjAwRs"
      },
      "outputs": [],
      "source": [
        "con_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7OvIzn4RBHSg"
      },
      "outputs": [],
      "source": [
        "hotels_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_SsGNexhBKx8"
      },
      "outputs": [],
      "source": [
        "con_data1=pd.merge(con_data,hotels_df,how='left',left_on='travelCode',right_on='travelCode')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OozzeNwaBYKz"
      },
      "outputs": [],
      "source": [
        "con_data1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3TLx0dvLBeEH"
      },
      "outputs": [],
      "source": [
        "con_data1.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ImQ88fSbB-PA"
      },
      "outputs": [],
      "source": [
        "con_data1.drop(['time','date_x','weekday','code','userCode_y','date_y'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sPTuxVxsCiRe"
      },
      "outputs": [],
      "source": [
        "con_data1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Czc-pIc5Cy8I"
      },
      "outputs": [],
      "source": [
        "con_categorical_data =con_data1.select_dtypes(exclude=['int64', 'float','int32'])\n",
        "con_numerical_data = con_data1.select_dtypes(include=['int64', 'float','int32'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KMXgsBk4DFy2"
      },
      "outputs": [],
      "source": [
        "le = LabelEncoder()\n",
        "con_categorical_data = con_categorical_data.apply(LabelEncoder().fit_transform)\n",
        "con_categorical_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DtaXTE12DN-w"
      },
      "outputs": [],
      "source": [
        "con_encode_df= pd.concat([con_categorical_data,con_numerical_data], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1NgB4_9mDS7-"
      },
      "outputs": [],
      "source": [
        "con_encode_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wnkcEWcODXIK"
      },
      "outputs": [],
      "source": [
        "con_encode_df.corr()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bSDZ9THgDcMH"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20,20))\n",
        "sns.heatmap(abs(round(con_encode_df.corr(),3)), annot=True, cmap=plt.cm.CMRmap)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*From the analysis of the variables and the correlation matrix, it is evident that there are no significant variables strongly correlated with our target variable.*"
      ],
      "metadata": {
        "id": "ofZCtRNRRFtu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Final dataset for Ml Model**"
      ],
      "metadata": {
        "id": "IslKFAicRmw5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oCISrQrQIzrX"
      },
      "outputs": [],
      "source": [
        "encode_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PqviH3fbJC-m"
      },
      "outputs": [],
      "source": [
        "final_df=encode_df[['from','to','flightType','agency','weekday_num','month','year','speed','price']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pQGRK39uK7-P"
      },
      "outputs": [],
      "source": [
        "final_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ii3ysH7SK_Zs"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "sns.heatmap(abs(round(final_df.corr(),3)), annot=True, cmap=plt.cm.CMRmap)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNVZ9zx19K6k"
      },
      "source": [
        "### 5. Data Transformation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bqkyxpk9NbMm"
      },
      "outputs": [],
      "source": [
        "cont_variables= [\"speed\",\"price\"]\n",
        "plt.figure(figsize=(20,6))\n",
        "print(\"Before Applying Transformation\")\n",
        "for n,col in enumerate(cont_variables):\n",
        "  plt.subplot(1,5,n+1)\n",
        "  sns.distplot(final_df[col])\n",
        "  plt.title(f'Distribution of {col}')\n",
        "  plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqoHp30x9hH9"
      },
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*No,The Data set no need of transformation*"
      ],
      "metadata": {
        "id": "raVgYQFVSIus"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B2t-9KEJRu8G"
      },
      "outputs": [],
      "source": [
        "# Creating 5 different copies to check the distribution of each of the variable\n",
        "test_df1=final_df.copy()\n",
        "test_df2=final_df.copy()\n",
        "test_df3=final_df.copy()\n",
        "test_df4=final_df.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "okbmjOfyRyvi"
      },
      "outputs": [],
      "source": [
        "test_df1['speed']=np.log(test_df1['speed']+1)\n",
        "test_df1['price']=np.log(test_df1['price']+1)\n",
        "\n",
        "# Checking the distribution of each continous variable by excluding 0 from our final dataframe\n",
        "plt.figure(figsize=(20,6))\n",
        "print(\"After Applying Transformation\")\n",
        "for n,col in enumerate(cont_variables):\n",
        "  plt.subplot(1,5,n+1)\n",
        "  sns.distplot(test_df1[col])\n",
        "  plt.title(f'Distribution of {col}')\n",
        "  plt.tight_layout()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "emDFBzAUSEcQ"
      },
      "outputs": [],
      "source": [
        "# Applying transformation on the above considered columns\n",
        "test_df2['speed']=1/(test_df2['speed']+1)\n",
        "test_df2['price']=1/(test_df2['price']+1)\n",
        "\n",
        "\n",
        "# Checking the distribution of each continous variable by excluding 0 from our final dataframe\n",
        "plt.figure(figsize=(20,6))\n",
        "print(\"After Applying Transformation\")\n",
        "for n,col in enumerate(cont_variables):\n",
        "  plt.subplot(1,5,n+1)\n",
        "  sns.distplot(test_df2[col])\n",
        "  plt.title(f'Distribution of {col}')\n",
        "  plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q0FTl5g9SPpY"
      },
      "outputs": [],
      "source": [
        " #Applying transformation on the above considered columns\n",
        "test_df3['speed']=(test_df3['speed'])**(1/2)\n",
        "test_df3['price']=(test_df3['price'])**(1/2)\n",
        "\n",
        "\n",
        "# Checking the distribution of each continous variable by excluding 0 from our final dataframe\n",
        "plt.figure(figsize=(20,6))\n",
        "print(\"After Applying Transformation\")\n",
        "for n,col in enumerate(cont_variables):\n",
        "  plt.subplot(1,5,n+1)\n",
        "  sns.distplot(test_df3[col])\n",
        "  plt.title(f'Distribution of {col}')\n",
        "  plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CsJVKv-2SeJs"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Applying transformation on the above considered columns\n",
        "test_df4['speed']=(test_df4['speed'])**(1/1.2)\n",
        "test_df4['price']=(test_df4['price'])**(1/1.2)\n",
        "\n",
        "\n",
        "# Checking the distribution of each continous variable by excluding 0 from our final dataframe\n",
        "plt.figure(figsize=(20,6))\n",
        "print(\"After Applying Transformation\")\n",
        "for n,col in enumerate(cont_variables):\n",
        "  plt.subplot(1,5,n+1)\n",
        "  sns.distplot(test_df4[col])\n",
        "  plt.title(f'Distribution of {col}')\n",
        "  plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMDnDkt2B6du"
      },
      "source": [
        "### 6. Data Scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dL9LWpySC6x_"
      },
      "outputs": [],
      "source": [
        "# Scaling your data\n",
        "# Separating \"x\" and \"y\" variables\n",
        "x= final_df.drop('price',axis=1)\n",
        "y= final_df[['price']]\n",
        "print(x.shape)\n",
        "print(y.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JxfCsXJbTxuv"
      },
      "outputs": [],
      "source": [
        "# Creating object\n",
        "std_regressor= StandardScaler()\n",
        "\n",
        "# Fit and Transform\n",
        "x= std_regressor.fit_transform(x)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "joblib.dump(std_regressor, '/content/std_regressor.pkl')"
      ],
      "metadata": {
        "id": "-d93WeonDMtv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiiVWRdJDDil"
      },
      "source": [
        "##### Which method have you used to scale you data and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*I used StandardScaler to scale our data because it standardizes features by removing the mean and scaling to unit variance, which helps improve the performance and convergence of many machine learning algorithms.*"
      ],
      "metadata": {
        "id": "tFIToTgzR1wK"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UUpS68QDMuG"
      },
      "source": [
        "### 7. Dimesionality Reduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kexQrXU-DjzY"
      },
      "source": [
        "##### Do you think that dimensionality reduction is needed? Explain Why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGRlBsSGDtTQ"
      },
      "source": [
        "*No need of dimensionality reduction process*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhH2vgX9EjGr"
      },
      "source": [
        "### 8. Data Splitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "outputs": [],
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely.\n",
        "# Split your data to train and test. Choose Splitting ratio wisely.\n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=10)\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjKvONjwE8ra"
      },
      "source": [
        "##### What data splitting ratio have you used and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      },
      "source": [
        "*I used an 80-20 splitting ratio because it provides a balanced approach for training and testing. This ratio ensures that 80% of the data is used for training the model, allowing it to learn from a substantial amount of data, while the remaining 20% is reserved for testing to evaluate the model's performance on unseen data.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1XJ9OREExlT"
      },
      "source": [
        "### 9. Handling Imbalanced Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFOzZv6IFROw"
      },
      "source": [
        "##### Do you think the dataset is imbalanced? Explain Why."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeKDIv7pFgcC"
      },
      "source": [
        "*No need*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfCC591jGiD4"
      },
      "source": [
        "## ***7. ML Model Implementation***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "19esftY5UIds"
      },
      "outputs": [],
      "source": [
        "# Defining the function that calculated regression metrics\n",
        "def regression_metrics(y_train_actual,y_train_pred,y_test_actual,y_test_pred):\n",
        "  print(\"-\"*50)\n",
        "  ## mean_absolute_error\n",
        "  MAE_train= mean_absolute_error(y_train,y_train_pred)\n",
        "  print(\"MAE on train is:\" ,MAE_train)\n",
        "  MAE_test= mean_absolute_error(y_test,y_test_pred)\n",
        "  print(\"MAE on test is:\" ,MAE_test)\n",
        "\n",
        "  print(\"-\"*50)\n",
        "\n",
        "  ## mean_squared_error\n",
        "  MSE_train= mean_squared_error(y_train, y_train_pred)\n",
        "  print(\"MSE on train is:\" ,MSE_train)\n",
        "  MSE_test  = mean_squared_error(y_test, y_test_pred)\n",
        "  print(\"MSE on test is:\" ,MSE_test)\n",
        "\n",
        "  print(\"-\"*50)\n",
        "\n",
        "  ## root_mean_squared_error\n",
        "  RMSE_train = np.sqrt(MSE_train)\n",
        "  print(\"RMSE on train is:\" ,RMSE_train)\n",
        "  RMSE_test = np.sqrt(MSE_test)\n",
        "  print(\"RMSE on test is:\" ,RMSE_test)\n",
        "\n",
        "  print(\"-\"*50)\n",
        "\n",
        "   ## mean_absolute_percentage_error\n",
        "  MAPE_train = mean_absolute_percentage_error(y_train, y_train_pred)*100\n",
        "  print(\"MAPE on train is:\" ,MAPE_train, \" %\")\n",
        "  MAPE_test = mean_absolute_percentage_error(y_test, y_test_pred)*100\n",
        "  print(\"MAPE on test is:\" ,MAPE_test, \" %\")\n",
        "\n",
        "  print(\"-\"*50)\n",
        "\n",
        "  ## r2_score\n",
        "  R2_train= r2_score(y_train,y_train_pred)\n",
        "  print(\"R2 on train is:\" ,R2_train)\n",
        "  R2_test= r2_score(y_test,y_test_pred)\n",
        "  print(\"R2 on test is:\" ,R2_test)\n",
        "\n",
        "  print(\"-\"*50)\n",
        "\n",
        "  Accuracy_train= 100- MAPE_train\n",
        "  print(\"Accuracy of train is:\" ,Accuracy_train, \" %\")\n",
        "  Accuracy_test= 100- MAPE_test\n",
        "  print(\"Accuracy of test is:\" ,Accuracy_test, \" %\")\n",
        "\n",
        "  print(\"-\"*50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sMD3jfLfUMS-"
      },
      "outputs": [],
      "source": [
        "# Defining the function that plots Evaluation Metric Score Chart\n",
        "def EvaluationMetricChart(yt,yp):\n",
        "   ''' Prints Evaluation Metrics Chart'''\n",
        "   #Plotting Actual and Predicted Values\n",
        "   plt.figure(figsize=(18,6))\n",
        "   plt.plot((yp)[:100])\n",
        "   plt.plot((np.array(yt)[:100]))\n",
        "   plt.legend([\"Predicted\",\"Actual\"])\n",
        "   plt.title('Actual and Predicted Time Duration')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      },
      "source": [
        "### ML Model - 1 Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "outputs": [],
      "source": [
        "# ML Model - 1 Implementation\n",
        "linear_regressor= LinearRegression()\n",
        "# Fit the Algorithm\n",
        "linear_regressor.fit(x_train,y_train)\n",
        "# Predict on the model\n",
        "y_pred_lr_train = linear_regressor.predict(x_train)\n",
        "y_pred_lr_test  = linear_regressor.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oM_mIuEwUW9w"
      },
      "outputs": [],
      "source": [
        "linear_regressor.coef_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oTEaQN1hUbdh"
      },
      "outputs": [],
      "source": [
        "# Calculating the regression metrics\n",
        "regression_metrics(y_train,y_pred_lr_train,y_test,y_pred_lr_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "outputs": [],
      "source": [
        "#Evaluation metrics Chart for Train set\n",
        "EvaluationMetricChart(y_train,y_pred_lr_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yyq9B3jRUxwk"
      },
      "outputs": [],
      "source": [
        "EvaluationMetricChart(y_test,y_pred_lr_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArJBuiUVfxKd"
      },
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*The linear regression model shows consistent performance between training and testing datasets. However, the relatively low R² and high MAPE suggest that the model's predictive performance is limited, indicating that further improvement or alternative modeling approaches may be needed to better capture the relationships in the data.*"
      ],
      "metadata": {
        "id": "PCv9CCsAVZmW"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      },
      "source": [
        "### ML Model - 2 Lasso Regularization\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GRmAkJ-pVJcF"
      },
      "outputs": [],
      "source": [
        "lasso= Lasso()\n",
        "# Defining parameters\n",
        "parameters_lasso = {\"alpha\": [1e-5,1e-4,1e-3,1e-2,1e-1,1,5], \"max_iter\":[7,8,9,10]}\n",
        "# Train the model\n",
        "lassoR = GridSearchCV(lasso, parameters_lasso, scoring='neg_mean_squared_error', cv=5)\n",
        "lassoR.fit(x_train,y_train)\n",
        "# Predict the output\n",
        "y_pred_lasso_train = lassoR.predict(x_train)\n",
        "y_pred_lasso_test  = lassoR.predict(x_test)\n",
        "# Printing the best parameters obtained by GridSearchCV\n",
        "print(f\"The best alpha value found out to be: {lassoR.best_params_}\")\n",
        "print(f\"Negative mean square error is: {lassoR.best_score_}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0uBlR9odVQIH"
      },
      "outputs": [],
      "source": [
        "# Calculating the regression metrics\n",
        "regression_metrics(y_train,y_pred_lasso_train,y_test,y_pred_lasso_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "outputs": [],
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "EvaluationMetricChart(y_train,y_pred_lasso_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v2HDWyIBVgyq"
      },
      "outputs": [],
      "source": [
        "#Evaluation metrics Chart for Test set\n",
        "EvaluationMetricChart(y_test,y_pred_lasso_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWYfwnehpsJ1"
      },
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*The Lasso Regression model shows performance metrics very similar to those of the linear regression model. The L1 regularization did not substantially change the MAE, MSE, RMSE, MAPE, R², or accuracy. This suggests that while Lasso helps with regularization and feature selection, it did not significantly enhance model performance or predictive power in this case. The low R² and high MAPE indicate that there is still room for improvement, possibly by exploring other models or tuning the regularization parameters.*"
      ],
      "metadata": {
        "id": "PGYrVi81WEcC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fze-IPXLpx6K"
      },
      "source": [
        "### ML Model - 3 Ridge Regularization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "outputs": [],
      "source": [
        "# ML Model - 3 Implementation\n",
        "ridge= Ridge()\n",
        "# Defining parameters\n",
        "parameters = {\"alpha\": [1e-1,1,5,7,10,11,14,15,16,17], \"max_iter\":[1,2,3]}\n",
        "# Fit the Algorithm\n",
        "ridgeR = GridSearchCV(ridge, parameters, scoring='neg_mean_squared_error', cv=3)\n",
        "ridgeR.fit(x_train,y_train)\n",
        "# Predict on the model\n",
        "y_pred_ridge_train = ridgeR.predict(x_train)\n",
        "y_pred_ridge_test = ridgeR.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r9rqNokHVstK"
      },
      "outputs": [],
      "source": [
        "# Calculating the regression metrics\n",
        "regression_metrics(y_train,y_pred_ridge_train,y_test,y_pred_ridge_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peH84E-NXxay"
      },
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*The Ridge Regression model shows performance metrics that are quite similar to those of the linear and Lasso regression models. The addition of L2 regularization helps in handling multicollinearity but does not substantially change MAE, MSE, RMSE, MAPE, or R². The consistent performance across models suggests that while Ridge Regression may improve stability and regularization, it has not significantly enhanced predictive performance or explained variance in the target variable. Further model tuning or exploration of alternative approaches may be necessary to achieve better results.*"
      ],
      "metadata": {
        "id": "HWaIwBFgW8ZB"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1xHXbswUVuZ"
      },
      "source": [
        "### ML Model - 4 ElasticNet Regularization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7N10xSDoV_4S"
      },
      "outputs": [],
      "source": [
        "# ML Model - 4 Implementation\n",
        "e_net= ElasticNet()\n",
        "# Defining parameters\n",
        "parameters_e_net = {\"alpha\": [1e-5,1e-4,1e-3,1e-2,1,5], \"max_iter\":[12,13,14,15]}\n",
        "\n",
        "# Train the model\n",
        "e_netR = GridSearchCV(e_net, parameters_e_net, scoring='neg_mean_squared_error', cv=5)\n",
        "e_netR.fit(x_train,y_train)\n",
        "\n",
        "# Predict on the model\n",
        "y_pred_e_net_train = e_netR.predict(x_train)\n",
        "y_pred_e_net_test = e_netR.predict(x_test)\n",
        "\n",
        "# Printing the best parameters obtained by GridSearchCV\n",
        "print(f\"The best alpha value found out to be: {e_netR.best_params_}\")\n",
        "print(f\"Negative mean square error is: {e_netR.best_score_}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IJ0uSpXLWEmy"
      },
      "outputs": [],
      "source": [
        "# Calculating the regression metrics\n",
        "regression_metrics(y_train,y_pred_e_net_train,y_test,y_pred_e_net_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7AN1z2sKpx6M"
      },
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*The Elastic Net Regression model shows performance metrics that are similar to those of the linear, Lasso, and Ridge regression models. The combination of L1 and L2 regularization did not significantly alter MAE, MSE, RMSE, MAPE, or R², suggesting that while Elastic Net provides regularization benefits, it did not substantially enhance the model's predictive performance or variance explanation. Further exploration of different models or hyperparameters may be necessary to achieve better results.*"
      ],
      "metadata": {
        "id": "4xxGwEw4XmYj"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjGYl2YCUdF9"
      },
      "source": [
        "### ML Model - 5 Light GBM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lq_gl_YZWQHJ"
      },
      "outputs": [],
      "source": [
        "# ML Model - 5 Implementation\n",
        "lgbmR = LGBMRegressor(boosting_type='gbdt', max_depth=120, learning_rate=0.1, n_estimators=500,  n_jobs=-1)\n",
        "lgbmR.fit(x_train, y_train)\n",
        "y_train_lgbmR_pred= lgbmR.predict(x_train)\n",
        "y_test_lgbmR_pred= lgbmR.predict(x_test)\n",
        "\n",
        "\n",
        "# Calculating the regression metrics\n",
        "regression_metrics(y_train,y_train_lgbmR_pred,y_test,y_test_lgbmR_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YlKJR5nnWcbX"
      },
      "outputs": [],
      "source": [
        "EvaluationMetricChart(y_train,y_train_lgbmR_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JqMBn00kWgoE"
      },
      "outputs": [],
      "source": [
        "#Evaluation metrics Chart for Test set\n",
        "EvaluationMetricChart(y_test,y_test_lgbmR_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRplsw0hX0vK"
      },
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*The LightGBM model demonstrates exceptional performance across all evaluation metrics.Low MAE, MSE, RMSE, and MAPE: Indicates accurate and reliable predictions with minimal errors.High R² Shows that the model explains a significant amount of variance in the data.High Accuracy Reflects the model’s effectiveness in making correct predictions.Overall, LightGBM outperforms previous models, showing its strength in handling regression tasks with high accuracy and low error rates.*"
      ],
      "metadata": {
        "id": "dRMpZGocX2P2"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PIHJqyupx6M"
      },
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "outputs": [],
      "source": [
        "# import ridge regression from sklearn library and RandomizedSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# Creating XGBoost instance\n",
        "lgbm= LGBMRegressor()\n",
        "\n",
        "# Defining parameters\n",
        "parameters={\"learning_rate\":[0.01,0.1],\"max_depth\":[120,125,150],\"n_estimators\":[500,600]}\n",
        "\n",
        "# Train the model\n",
        "lgbm_rand_R= RandomizedSearchCV(lgbm,parameters,scoring='neg_mean_squared_error',n_jobs=-1,cv=3,verbose=3)\n",
        "lgbm_rand_R.fit(x_train,y_train)\n",
        "\n",
        "# Predict the output\n",
        "y_train_rand_lgbm_pred = lgbm_rand_R.predict(x_train)\n",
        "y_test_rand_lgbm_pred = lgbm_rand_R.predict(x_test)\n",
        "\n",
        "# Printing the best parameters obtained by GridSearchCV\n",
        "print(f\"The best alpha value found out to be: {lgbm_rand_R.best_params_}\")\n",
        "print(f\"Negative mean square error is: {lgbm_rand_R.best_score_}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2E6i4XZZce5"
      },
      "outputs": [],
      "source": [
        "# Calculating the regression metrics\n",
        "regression_metrics(y_train,y_train_rand_lgbm_pred,y_test,y_test_rand_lgbm_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pjps9I-AYTb3"
      },
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*The evaluation metrics after applying Random Search CV show that the model’s performance has been consistently strong.*\n",
        "\n",
        "*Random Search CV was chosen because it is well-suited for optimizing hyperparameters efficiently, especially in cases with large and complex hyperparameter spaces. The strong performance metrics confirm that the hyperparameter tuning was effective in improving the model’s accuracy and reliability.*"
      ],
      "metadata": {
        "id": "HB4pMvyIZKF9"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-Hs256DUssU"
      },
      "source": [
        "### ML Model - 6 XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g5JMP_ghnF3r"
      },
      "outputs": [],
      "source": [
        "# ML Model - 6 Implementation\n",
        "xgbR = XGBRegressor(learning_rate=0.2, max_depth=10)\n",
        "xgbR.fit(x_train, y_train)\n",
        "y_train_xgbR_pred= xgbR.predict(x_train)\n",
        "y_test_xgbR_pred= xgbR.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "At5jlVDtnJRh"
      },
      "outputs": [],
      "source": [
        "# Calculating the regression metrics\n",
        "regression_metrics(y_train,y_train_xgbR_pred,y_test,y_test_xgbR_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRGnvVC5ZhNZ"
      },
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*XGBoost demonstrates excellent performance across all metrics, indicating a highly accurate and reliable model. The model performs well on both the training and testing datasets, with minimal error and high predictive power. The improvements in MAE, MSE, RMSE, MAPE, and R² compared to previous models highlight the effectiveness of XGBoost in capturing the underlying patterns in the data and making precise predictions.*\n",
        "\n",
        "*Overall, XGBoost is a robust model choice for this regression task, providing strong performance metrics that signify high accuracy and minimal error in predictions.*"
      ],
      "metadata": {
        "id": "8R2d-p-VZgpL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cAFBxXGRnOoX"
      },
      "outputs": [],
      "source": [
        "# import ridge regression from sklearn library and RandomizedSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# Creating XGBoost instance\n",
        "xgb= XGBRegressor()\n",
        "\n",
        "# Defining parameters\n",
        "parameters={\"learning_rate\":[0.01, 0.1],\"max_depth\":[4,6,8]}\n",
        "\n",
        "# Train the model\n",
        "xgb_Rand_R= GridSearchCV(xgb,parameters,scoring='neg_mean_squared_error',n_jobs=-1,cv=3,verbose=2)\n",
        "xgb_Rand_R.fit(x_train,y_train)\n",
        "\n",
        "# Predict the output\n",
        "y_train_rand_xgbR_pred = xgb_Rand_R.predict(x_train)\n",
        "y_test_rand_xgbR_pred = xgb_Rand_R.predict(x_test)\n",
        "\n",
        "# Printing the best parameters obtained by GridSearchCV\n",
        "print(f\"The best alpha value found out to be: {xgb_Rand_R.best_params_}\")\n",
        "print(f\"Negative mean square error is: {xgb_Rand_R.best_score_}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VB6v8cv2nSE1"
      },
      "outputs": [],
      "source": [
        "# Calculating the regression metrics\n",
        "regression_metrics(y_train,y_train_rand_xgbR_pred,y_test,y_test_rand_xgbR_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_o4qcbD7nr59"
      },
      "outputs": [],
      "source": [
        "#Evaluation metrics Chart for Train set\n",
        "EvaluationMetricChart(y_train,y_train_xgbR_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rPEogidFnxIH"
      },
      "outputs": [],
      "source": [
        "#Evaluation metrics Chart for Test set\n",
        "EvaluationMetricChart(y_test,y_test_xgbR_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GcbqrMNYM5A"
      },
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*The evaluation metrics after applying Random Search CV show that the model’s performance has been consistently strong.*\n",
        "\n",
        "*Random Search CV was chosen because it is well-suited for optimizing hyperparameters efficiently, especially in cases with large and complex hyperparameter spaces. The strong performance metrics confirm that the hyperparameter tuning was effective in improving the model’s accuracy and reliability.*"
      ],
      "metadata": {
        "id": "vV5erg5bbIc4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "29d9tiZ7-TLj"
      },
      "outputs": [],
      "source": [
        "# Storing different regression metrics in order to make dataframe\n",
        "Models   = [\"Linear Regression\",\"Lasso Regression\",\"Ridgde Regression\",\n",
        "            \"Elastic Net Regression\",\"LightGBM\",\"XGboost\"]\n",
        "MAE      = [250.13,250.13,250.13,250.13,23.81,23.35]\n",
        "MSE      = [97548.73,97548.73,97548.77,97548.76,900.92,899.44]\n",
        "RMSE     = [312.32,312.30,312.30,312.32,30.015,29.990]\n",
        "MAPE     = [30.40,30.40,30.41,30.41,2.76,2.69]\n",
        "r2       = [0.2622,0.2622,0.2625,0.2622,0.9931,0.9930]\n",
        "accuracy = [69.59,69.59,69.54,69.59,99.293,99.700]\n",
        "\n",
        "# Create dataframe from the lists\n",
        "data = {'MODEL': Models,\n",
        "          'MAE': MAE,\n",
        "          'MSE': MSE,\n",
        "         'RMSE': RMSE,\n",
        "         'MAPE': MAPE,\n",
        "           'R2': r2,\n",
        "     'Accuracy': accuracy}\n",
        "\n",
        "Metric_df = pd.DataFrame(data)\n",
        "\n",
        "# Printing dataframe\n",
        "Metric_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_CCil-SKHpo"
      },
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***To gauge the positive business impact of a predictive model, the following evaluation metrics are particularly important:***\n",
        "\n",
        "**1. Mean Absolute Error (MAE)**\n",
        "\n",
        "*MAE provides a straightforward measure of prediction accuracy by calculating the average magnitude of errors. Lower MAE values mean that predictions are closer to the actual values, which translates to better decision-making and customer satisfaction.*\n",
        "\n",
        "**2. Mean Squared Error (MSE)**\n",
        "\n",
        "*MSE emphasizes larger errors more than smaller ones due to squaring the differences. This metric helps in understanding the impact of outliers and the overall precision of the model. Lower MSE indicates fewer and smaller errors, which can lead to more effective strategies and cost savings.*\n",
        "\n",
        "**3. Root Mean Squared Error (RMSE)**\n",
        "\n",
        "*RMSE is the square root of MSE and provides an error measure in the same units as the target variable, making it easier to interpret. Lower RMSE values indicate that the model’s predictions are generally close to the actual values, enhancing operational efficiency and reducing potential losses.*\n",
        "\n",
        "**4. Mean Absolute Percentage Error (MAPE)**\n",
        "\n",
        "*MAPE measures prediction accuracy as a percentage, which is useful for understanding the relative error in percentage terms. A lower MAPE indicates that the model’s predictions are more accurate relative to the magnitude of the target values, leading to better financial forecasting and budget management.*\n",
        "\n",
        "**5. R-squared (R²)**\n",
        "\n",
        "*R² shows the proportion of variance in the target variable explained by the model. A higher R² value signifies that the model explains a large portion of the variance, leading to more reliable predictions and informed business decisions.*\n",
        "\n",
        "**6. Accuracy**\n",
        "\n",
        "*While often used in classification tasks, accuracy in regression contexts can refer to the percentage of predictions that fall within an acceptable range of error. High accuracy means the model is effective in making precise predictions, which can positively impact strategy formulation and operational planning.*"
      ],
      "metadata": {
        "id": "0Ecp6FAlblpr"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBFFvTBNJzUa"
      },
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      },
      "source": [
        "*XGBoost is chosen as the final prediction model due to its superior performance across most evaluation metrics. It demonstrates the lowest MAE, MSE, RMSE, and MAPE, and has the highest R² value, reflecting its ability to make accurate predictions and effectively capture the relationships within the data. This makes it a robust choice for achieving reliable and precise results in the given prediction task.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvGl1hHyA_VK"
      },
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnvVTiIxBL-C"
      },
      "source": [
        "*XGBoost is a powerful and flexible model that combines the strengths of multiple decision trees. By analyzing feature importance, we can gain insights into which features most significantly affect the model's predictions, aiding in feature selection, model interpretation, and enhancing the understanding of underlying data patterns.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyNgTHvd2WFk"
      },
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KH5McJBi2d8v"
      },
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle"
      ],
      "metadata": {
        "id": "6_imi1XL90JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "outputs": [],
      "source": [
        "# Save the File\n",
        "filename='flight_price_prediction_regression.pkl'\n",
        "\n",
        "# serialize process (wb=write byte)\n",
        "pickle.dump(xgb_Rand_R,open(filename,'wb'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      },
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "outputs": [],
      "source": [
        "# Load the File and predict unseen data.\n",
        "# Load the File and predict unseen data.\n",
        "Regression_model= pickle.load(open(filename,'rb'))\n",
        "\n",
        "# Predicting the unseen data(test set)\n",
        "Regression_model.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_rand_lgbm_pred"
      ],
      "metadata": {
        "id": "DqqalY95-E0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "lMePZCgyddpC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy the file to Google Drive\n",
        "!cp flight_price_prediction_regression.pkl '/content/drive/MyDrive'\n",
        "print('Model saved to Google Drive')"
      ],
      "metadata": {
        "id": "U9ubk4l3Gv5i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Kee-DAl2viO"
      },
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCX9965dhzqZ"
      },
      "source": [
        "# **Conclusion**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      },
      "source": [
        "**Project Overview:**\n",
        "\n",
        "*In this project, I analyzed flight price data to build predictive models for estimating flight prices. The process involved various stages, from data wrangling and exploratory data analysis (EDA) to feature engineering, model building, and evaluation.*\n",
        "\n",
        "**Data Analysis:**\n",
        "\n",
        "**Exploratory Data Analysis (EDA):**\n",
        "\n",
        "**Price Distribution:** *Analyzed the distribution of flight prices and identified that most ticket prices fall between $600 and $900.*\n",
        "\n",
        "**Flight Types and Agencies:** *Evaluated the market share of flight types and agencies, finding that first-class tickets had the highest share, while agencies like \"Flying Drops\" had higher average prices despite a smaller market share.*\n",
        "\n",
        "**Distance and Time:** *Investigated the correlation between flight distance, time, and price, noting a positive correlation between distance and price.*\n",
        "\n",
        "**Feature Engineering:**\n",
        "\n",
        "*Created features such as flight route, speed, and temporal components (e.g., day of the week, month) to enhance the model's predictive power.*\n",
        "\n",
        "*Applied scaling to normalize the data and ensure consistent feature ranges.*\n",
        "\n",
        "**Modeling:**\n",
        "\n",
        "**Linear Regression:**\n",
        "\n",
        "**Performance:** *Provided baseline performance metrics with moderate accuracy. MAE was around $250, and the R² score was approximately 0.262, indicating limited predictive power.*\n",
        "\n",
        "**Regularization Models (Lasso, Ridge, Elastic Net):**\n",
        "\n",
        "**Performance:** *Improved performance metrics slightly but did not significantly outperform the baseline model. These models helped in managing overfitting but showed similar accuracy and R² scores.*\n",
        "\n",
        "**LightGBM:**\n",
        "\n",
        "**Performance:** *Showed significant improvements with MAE around $23.81 and R² close to 0.993. The model demonstrated high accuracy and effectively handled the dataset’s complexity.*\n",
        "\n",
        "**XGBoost:**\n",
        "\n",
        "**Performance:** *Delivered excellent results with MAE of $23.87 and an R² score of 0.993. It outperformed other models in terms of accuracy and predictive power.*\n",
        "\n",
        "**Cross-Validation and Hyperparameter Tuning:**\n",
        "\n",
        "**Results:** *Cross-validation and random search for hyperparameter optimization helped to fine-tune the models and achieve consistent performance with XGBoost.*\n",
        "\n",
        "**Model Selection:**\n",
        "\n",
        "*XGBoost was chosen as the final model due to its superior performance across multiple metrics. It consistently delivered high accuracy, low error rates, and strong predictive power, making it the most suitable choice for this project.*\n",
        "\n",
        "**Feature Importance:**\n",
        "\n",
        "*XGBoost's feature importance analysis revealed key variables impacting flight prices. Variables such as distance and total time were identified as crucial factors in predicting prices, providing valuable insights for further analysis and model refinement.*"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "6PZkiCOXSslq"
      }
    }
  ]
}